import speech_recognition as sr
import pygame
import google.generativeai as genai
import edge_tts
import asyncio
import re
from io import BytesIO
from flask import Flask, request, jsonify
from flask_cors import CORS
import base64
import threading
import queue

# === Gemini config ===
genai.configure(api_key="AIzaSyBGWplwpUQUIUZ9QAg3dPMj5poFeNr1qu8")
gemini_model = genai.GenerativeModel("gemini-2.0-flash")

app = Flask(__name__)
CORS(app)

pygame.mixer.init()
history = []

def clean_text(text):
    return re.sub(r"[*_`>#+-]", "", text).strip()

# === Edge TTS t·∫°o audio base64 ===
async def generate_audio_base64(text, voice="vi-VN-HoaiMyNeural"):
    mp3_fp = BytesIO()
    communicate = edge_tts.Communicate(text, voice)
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            mp3_fp.write(chunk["data"])
    mp3_fp.seek(0)
    audio_base64 = base64.b64encode(mp3_fp.read()).decode('utf-8')
    return audio_base64

# === Conversation Memory Management ===
conversation_memory = {
    'session_started': False,
    'topics_discussed': [],
    'student_questions': [],
    'current_lesson': None,
    'greeting_count': 0,
    'last_greeting_time': None,
    'conversation_context': []
}

def get_conversation_context():
    """Get relevant conversation context for AI"""
    context_parts = []

    if conversation_memory['current_lesson']:
        context_parts.append(f"B√†i h·ªçc hi·ªán t·∫°i: {conversation_memory['current_lesson']}")

    if conversation_memory['topics_discussed']:
        recent_topics = conversation_memory['topics_discussed'][-3:]  # Last 3 topics
        context_parts.append(f"C√°c ch·ªß ƒë·ªÅ ƒë√£ th·∫£o lu·∫≠n: {', '.join(recent_topics)}")

    if conversation_memory['student_questions']:
        recent_questions = conversation_memory['student_questions'][-2:]  # Last 2 questions
        context_parts.append(f"C√¢u h·ªèi g·∫ßn ƒë√¢y: {'; '.join(recent_questions)}")

    return "\n".join(context_parts)

def update_conversation_memory(user_text, page_content=""):
    """Update conversation memory with new interaction"""
    import time

    # Mark session as started
    if not conversation_memory['session_started']:
        conversation_memory['session_started'] = True

    # Extract lesson from page content
    if page_content and "B√†i" in page_content:
        lesson_match = page_content.split('\n')[0] if '\n' in page_content else page_content[:50]
        if lesson_match != conversation_memory['current_lesson']:
            conversation_memory['current_lesson'] = lesson_match

    # Store student question
    conversation_memory['student_questions'].append(user_text)
    if len(conversation_memory['student_questions']) > 5:
        conversation_memory['student_questions'] = conversation_memory['student_questions'][-5:]

    # Store conversation context
    conversation_memory['conversation_context'].append(f"H·ªçc sinh: {user_text}")
    if len(conversation_memory['conversation_context']) > 10:
        conversation_memory['conversation_context'] = conversation_memory['conversation_context'][-10:]

    # Extract topics from user question
    chemistry_keywords = ['nguy√™n t·ª≠', 'ph√¢n t·ª≠', 'ion', 'h√≥a tr·ªã', 'ph∆∞∆°ng tr√¨nh', 'ph·∫£n ·ª©ng', 'ch·∫•t', 'h·ªón h·ª£p', 'nguy√™n t·ªë']
    for keyword in chemistry_keywords:
        if keyword in user_text.lower() and keyword not in conversation_memory['topics_discussed']:
            conversation_memory['topics_discussed'].append(keyword)
            if len(conversation_memory['topics_discussed']) > 10:
                conversation_memory['topics_discussed'] = conversation_memory['topics_discussed'][-10:]

def should_greet():
    """Determine if AI should greet based on conversation context"""
    import time

    # Never greet if already greeted more than once
    if conversation_memory['greeting_count'] >= 1:
        return False

    # Only greet at the very beginning
    if len(conversation_memory['student_questions']) <= 1:
        return True

    return False

def mark_greeting_used():
    """Mark that a greeting was used"""
    import time
    conversation_memory['greeting_count'] += 1
    conversation_memory['last_greeting_time'] = time.time()

# === X·ª≠ l√Ω h·ªôi tho·∫°i Gemini ===
def get_gemini_reply(user_text, page_content=""):
    try:
        # Update conversation memory
        update_conversation_memory(user_text, page_content)

        # Get conversation context
        conversation_context = get_conversation_context()

        # Build context
        context_parts = []
        if page_content:
            context_parts.append(f"N·ªôi dung trang hi·ªán t·∫°i: {page_content}")
        if conversation_context:
            context_parts.append(f"B·ªëi c·∫£nh cu·ªôc tr√≤ chuy·ªán: {conversation_context}")

        context = "\n".join(context_parts)

        # Determine if greeting is needed
        greeting_needed = should_greet()

        # Build intelligent prompt based on conversation context
        recent_context = "\n".join(conversation_memory['conversation_context'][-3:]) if conversation_memory['conversation_context'] else ""

        response = gemini_model.generate_content(
            f"""
            B·∫°n l√† gi√°o vi√™n H√≥a h·ªçc th√¥ng minh, t·ª± nhi√™n, d·∫°y h·ªçc sinh c·∫•p 2.

            NGUY√äN T·∫ÆC QUAN TR·ªåNG:
            - Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch (t·ªëi ƒëa 70 t·ª´)
            - ƒê∆∞a ra v√≠ d·ª• th·ª±c t·∫ø c·ª• th·ªÉ ƒë·ªÉ h·ªçc sinh d·ªÖ hi·ªÉu
            - TUY·ªÜT ƒê·ªêI KH√îNG h·ªèi l·∫°i h·ªçc sinh ("C√°c em c√≥ hi·ªÉu kh√¥ng?", "C√≤n c√¢u h·ªèi n√†o kh√¥ng?")
            - TUY·ªÜT ƒê·ªêI KH√îNG ch√†o h·ªèi n·∫øu ƒë√£ ch√†o r·ªìi
            - Tr·∫£ l·ªùi t·ª± nhi√™n, th√¥ng minh nh∆∞ gi√°o vi√™n th·∫≠t
            - T·∫≠p trung v√†o gi·∫£i th√≠ch ki·∫øn th·ª©c v·ªõi v√≠ d·ª• c·ª• th·ªÉ
            - S·ª≠ d·ª•ng ng√¥n ng·ªØ ƒë∆°n gi·∫£n, g·∫ßn g≈©i

            B·ªêI C·∫¢NH CU·ªòC TR√í CHUY·ªÜN G·∫¶N ƒê√ÇY:
            {recent_context}

            N·ªòI DUNG B√ÄI H·ªåC:
            {context}

            C√¢u h·ªèi c·ªßa h·ªçc sinh: "{user_text}"

            {"Ch√†o em ng·∫Øn g·ªçn (1 c√¢u) r·ªìi" if greeting_needed else ""}
            Tr·∫£ l·ªùi tr·ª±c ti·∫øp v·ªõi v√≠ d·ª• th·ª±c t·∫ø c·ª• th·ªÉ. KH√îNG h·ªèi l·∫°i.
            """,
            generation_config=genai.types.GenerationConfig(
                temperature=0.6,
                top_p=0.9,
                top_k=30
            )
        )

        reply = response.text.strip()

        # Mark greeting as used if it was needed
        if greeting_needed:
            mark_greeting_used()

        # Store AI response in conversation context
        conversation_memory['conversation_context'].append(f"Th·∫ßy: {reply}")
        if len(conversation_memory['conversation_context']) > 10:
            conversation_memory['conversation_context'] = conversation_memory['conversation_context'][-10:]

        return reply
    except Exception as e:
        print(f"Gemini error: {e}")
        return "Th·∫ßy ƒëang b·∫≠n ch√∫t, em ch·ªù t√≠ nh√©!"

# Th√™m voice recognition
recognizer = sr.Recognizer()
microphone = sr.Microphone()
audio_queue = queue.Queue()

def listen_for_voice():
    """Background thread ƒë·ªÉ l·∫Øng nghe voice input"""
    with microphone as source:
        recognizer.adjust_for_ambient_noise(source)
    
    while True:
        try:
            with microphone as source:
                print("üé§ Listening for voice input...")
                audio = recognizer.listen(source, timeout=1, phrase_time_limit=5)
            
            try:
                # Nh·∫≠n d·∫°ng ti·∫øng Vi·ªát
                text = recognizer.recognize_google(audio, language='vi-VN')
                print(f"üó£Ô∏è Voice input: {text}")
                audio_queue.put(text)
            except sr.UnknownValueError:
                pass  # Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c
            except sr.RequestError as e:
                print(f"Voice recognition error: {e}")
                
        except sr.WaitTimeoutError:
            pass  # Timeout, ti·∫øp t·ª•c l·∫Øng nghe

# Kh·ªüi ƒë·ªông voice listener thread
voice_thread = threading.Thread(target=listen_for_voice, daemon=True)
voice_thread.start()

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        user_message = data.get('message', '')
        page_content = data.get('pageContent', '')
        
        if not user_message:
            return jsonify({'error': 'No message provided'}), 400
        
        # L∆∞u l·ªãch s·ª≠
        history.append(f"H·ªçc sinh: {user_message}")
        
        # Gemini tr·∫£ l·ªùi
        reply = get_gemini_reply(user_message, page_content)
        history.append(f"Th·∫ßy: {reply}")
        
        # T·∫°o audio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_base64 = loop.run_until_complete(generate_audio_base64(clean_text(reply)))
        loop.close()
        
        return jsonify({
            'reply': reply,
            'audio': audio_base64,
            'timestamp': str(asyncio.get_event_loop().time())
        })
        
    except Exception as e:
        print(f"Chat error: {e}")
        return jsonify({'error': 'Internal server error'}), 500

@app.route('/read-page', methods=['POST'])
def read_page():
    try:
        data = request.json
        page_content = data.get('pageContent', '')
        
        if not page_content:
            reply = "Kh√¥ng c√≥ n·ªôi dung ƒë·ªÉ ƒë·ªçc tr√™n trang n√†y."
        else:
            reply = f"T√¥i s·∫Ω ƒë·ªçc n·ªôi dung trang n√†y cho b·∫°n. {page_content}"
        
        # T·∫°o audio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_base64 = loop.run_until_complete(generate_audio_base64(clean_text(reply)))
        loop.close()
        
        return jsonify({
            'reply': reply,
            'audio': audio_base64
        })
        
    except Exception as e:
        print(f"Read page error: {e}")
        return jsonify({'error': 'Internal server error'}), 500

@app.route('/read-teaching-script', methods=['POST'])
def read_teaching_script():
    """Endpoint ƒë·ªÉ ƒë·ªçc teaching script v·ªõi voice assistant"""
    try:
        data = request.json
        script = data.get('script', '')
        page_number = data.get('pageNumber', 1)

        if not script:
            return jsonify({'error': 'No script provided'}), 400

        print(f"üé§ Reading teaching script for page {page_number}")
        print(f"üìñ Script length: {len(script)} characters")

        # T·∫°o audio v·ªõi Edge TTS
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_base64 = loop.run_until_complete(generate_audio_base64(clean_text(script), voice="vi-VN-HoaiMyNeural"))
        loop.close()

        return jsonify({
            'success': True,
            'audio': audio_base64,
            'pageNumber': page_number,
            'scriptLength': len(script)
        })

    except Exception as e:
        print(f"‚ùå Error in read_teaching_script: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy'})

@app.route('/voice-input', methods=['GET'])
def get_voice_input():
    """Endpoint ƒë·ªÉ l·∫•y voice input"""
    try:
        if not audio_queue.empty():
            voice_text = audio_queue.get_nowait()
            return jsonify({
                'text': voice_text,
                'hasInput': True
            })
        else:
            return jsonify({
                'text': '',
                'hasInput': False
            })
    except Exception as e:
        print(f"Voice input error: {e}")
        return jsonify({
            'text': '',
            'hasInput': False,
            'error': str(e)
        })

@app.route('/start-voice-listening', methods=['POST'])
def start_voice_listening():
    """B·∫Øt ƒë·∫ßu l·∫Øng nghe voice"""
    try:
        # Clear queue
        while not audio_queue.empty():
            audio_queue.get_nowait()
        
        return jsonify({'status': 'listening'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/stop-voice-listening', methods=['POST'])
def stop_voice_listening():
    """D·ª´ng l·∫Øng nghe voice"""
    try:
        # Clear queue
        while not audio_queue.empty():
            audio_queue.get_nowait()
            
        return jsonify({'status': 'stopped'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == "__main__":
    print("=" * 50)
    print("ü§ñ AI Teaching Assistant Server Starting...")
    print("üìö Gemini AI: Ready")
    print("üîä Edge TTS: Ready")
    print("üåê Server: http://localhost:5000")
    print("üîó Health Check: http://localhost:5000/health")
    print("=" * 50)

    try:
        app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)
    except Exception as e:
        print(f"‚ùå Failed to start server: {e}")
        print("üí° Make sure port 5000 is not in use")
